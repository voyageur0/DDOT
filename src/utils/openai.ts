import OpenAI from 'openai';
import { exponentialRetry } from './retry';

// Initialisation conditionnelle d'OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'sk-dummy-key-for-development',
});

export async function chatCompletion(
  zone: string,
  reglement: string,
  parcelLabel: string,
): Promise<string> {
  // Fonction helper pour choisir le mod√®le avec fallback
  const getModel = async (): Promise<string> => {
    try {
      // Test rapide avec gpt-4o-mini
      await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [{ role: 'user', content: 'test' }],
        max_tokens: 1
      });
      return 'gpt-4o-mini';
    } catch (error: any) {
      if (error.status === 404 || error.message?.includes('gpt-4o-mini')) {
        return 'gpt-3.5-turbo';
      }
      throw error;
    }
  };

  const selectedModel = await getModel();
  console.log(`ü§ñ Mod√®le s√©lectionn√© pour analyse simple: ${selectedModel}`);
  
  const response = await exponentialRetry(async () => {
    const completion = await openai.chat.completions.create({
      model: selectedModel,
      messages: [
        {
          role: 'system',
          content:
            'Tu es un juriste sp√©cialis√© en droit de la construction valaisan. R√©ponds de fa√ßon concise et exhaustive, en fran√ßais.',
        },
        {
          role: 'user',
          content: `ZONE: ${zone}\n\nR√àGLEMENT:\n${reglement}\n\nQUESTION: Quelles contraintes s'appliquent √† la parcelle ${parcelLabel} ?`,
        },
      ],
    });
    return completion.choices[0].message.content ?? '';
  });
  return response;
}

/**
 * Analyse approfondie avec recherche multi-√©tapes (simulation de la recherche approfondie ChatGPT)
 * Utilise plusieurs appels pour une analyse compl√®te et d√©taill√©e
 * Essaie d'abord o3, puis bascule sur o3-mini si non disponible
 */
export async function deepSearchAnalysis(
  zone: string,
  reglement: string,
  parcelLabel: string,
  additionalContext?: string
): Promise<string> {
  console.log('üîç D√©marrage de l\'analyse approfondie pour', parcelLabel);
  
  // Fonction helper pour choisir le mod√®le avec fallback
  const getModel = async (): Promise<string> => {
    try {
      // Test rapide avec gpt-4o-mini
      await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [{ role: 'user', content: 'test' }],
        max_tokens: 1
      });
      console.log('‚úÖ Mod√®le gpt-4o-mini disponible');
      return 'gpt-4o-mini';
          } catch (error: any) {
        if (error.status === 404 || error.message?.includes('gpt-4o-mini')) {
          console.log('‚ö†Ô∏è Mod√®le gpt-4o-mini non disponible, utilisation de gpt-3.5-turbo');
          return 'gpt-3.5-turbo';
        }
        throw error;
      }
  };
  
  try {
    const selectedModel = await getModel();
    console.log(`ü§ñ Mod√®le s√©lectionn√©: ${selectedModel}`);
    
    // √âtape 1: Analyse pr√©liminaire du zonage
    const zoningAnalysis = await exponentialRetry(async () => {
      const completion = await openai.chat.completions.create({
        model: selectedModel,
        messages: [
          {
            role: 'system',
            content: 'Tu es un expert en urbanisme valaisan. Analyse en d√©tail les implications du zonage.',
          },
          {
            role: 'user',
            content: `Analyse approfondie du zonage "${zone}" en Valais. Explique toutes les contraintes, possibilit√©s et restrictions de ce type de zone.`,
          },
        ],
      });
      return completion.choices[0].message.content ?? '';
    });

    // √âtape 2: Analyse d√©taill√©e du r√®glement
    const regulationAnalysis = await exponentialRetry(async () => {
      const completion = await openai.chat.completions.create({
        model: selectedModel,
        messages: [
          {
            role: 'system',
            content: 'Tu es un juriste sp√©cialis√© en droit de la construction. Analyse chaque article du r√®glement.',
          },
          {
            role: 'user',
            content: `Analyse article par article ce r√®glement communal:\n\n${reglement}\n\nIdentifie tous les points critiques, exceptions, et contraintes sp√©cifiques.`,
          },
        ],
      });
      return completion.choices[0].message.content ?? '';
    });

    // √âtape 3: Synth√®se crois√©e et recommandations
    const contextSection = additionalContext ? `CONTEXTE ADDITIONNEL: ${additionalContext}\n\n` : '';
    const prompt = `PARCELLE: ${parcelLabel}
ZONE: ${zone}
${contextSection}ANALYSE DU ZONAGE:
${zoningAnalysis}

ANALYSE DU R√àGLEMENT:
${regulationAnalysis}

Mission: Synth√©tise ces analyses pour fournir:
1. Un r√©sum√© ex√©cutif des contraintes principales
2. Les opportunit√©s de d√©veloppement
3. Les risques juridiques identifi√©s
4. Des recommandations concr√®tes pour le propri√©taire
5. Les d√©marches administratives n√©cessaires

Sois pr√©cis, actionnable et structure ta r√©ponse clairement.`;

    const finalSynthesis = await exponentialRetry(async () => {
      const completion = await openai.chat.completions.create({
        model: selectedModel,
        messages: [
          {
            role: 'system',
            content: 'Tu es un consultant expert en d√©veloppement immobilier valaisan. Fournis une synth√®se actionnable et des recommandations pr√©cises.',
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
      });
      return completion.choices[0].message.content ?? '';
    });

    console.log('‚úÖ Analyse approfondie termin√©e pour', parcelLabel, 'avec mod√®le', selectedModel);
    return finalSynthesis;

  } catch (error) {
    console.error('‚ùå Erreur lors de l\'analyse approfondie:', error);
    // Fallback vers l'analyse simple
    return await chatCompletion(zone, reglement, parcelLabel);
  }
}

// Helper g√©n√©rique pour tout appel simple depuis d'autres modules
export async function callOpenAI(params: {
  model?: string;
  temperature?: number;
  messages: { role: 'system' | 'user' | 'assistant'; content: string }[];
  max_tokens?: number;
  reasoning_effort?: 'low' | 'medium' | 'high';
}) {
  let {
    model = 'gpt-4o',
    temperature = 0,
    messages,
    max_tokens = 1000,
    reasoning_effort = 'medium'
  } = params;

  // Log du mod√®le utilis√©
  console.log(`ü§ñ Utilisation du mod√®le: ${model}`);

  try {
    // Les mod√®les o1 et o3 ont des restrictions sp√©ciales
    const isO3Model = model === 'o3' || model === 'o3-mini';
    const isO1Model = model === 'o1' || model === 'o1-mini';
    const isReasoningModel = isO3Model || isO1Model;
    
    if (isReasoningModel) {
      // Mod√®les de raisonnement: pas de system message, pas de temperature
      console.log(`üß† Mod√®le de raisonnement ${model} avec effort: ${reasoning_effort}`);
      
      // Convertir le system message en user message
      const reasoningMessages = messages.map(msg => {
        if (msg.role === 'system') {
          return { 
            role: 'user' as const, 
            content: `Instructions: ${msg.content}\n\n` 
          };
        }
        return msg;
      });
      
      // Fusionner les messages user cons√©cutifs
      const mergedMessages: typeof messages = [];
      for (const msg of reasoningMessages) {
        if (msg.role === 'user' && mergedMessages.length > 0 && mergedMessages[mergedMessages.length - 1].role === 'user') {
          mergedMessages[mergedMessages.length - 1].content += '\n\n' + msg.content;
        } else {
          mergedMessages.push(msg);
        }
      }
      
      // Pour o3/o3-mini, utiliser reasoning_effort
      if (isO3Model) {
        return await exponentialRetry(async () => {
          const requestParams: any = {
            model,
            messages: mergedMessages,
            reasoning_effort
          };
          
          console.log(`üìä Appel o3 avec reasoning_effort=${reasoning_effort}`);
          return await openai.chat.completions.create(requestParams);
        });
      } else {
        // Pour o1/o1-mini, on peut utiliser max_completion_tokens
        return await exponentialRetry(async () => {
          return await openai.chat.completions.create({
            model,
            messages: mergedMessages,
            max_completion_tokens: Math.min(max_tokens, 32768)
          });
        });
      }
    } else {
      // Mod√®les standards (gpt-4o, etc.)
      return await exponentialRetry(async () => {
        return await openai.chat.completions.create({
          model,
          temperature,
          messages,
          max_tokens
        });
      });
    }
  } catch (error: any) {
    // Fallback vers gpt-4o si le mod√®le n'est pas disponible
    if (error.status === 404 || error.status === 400) {
      console.log(`‚ö†Ô∏è Mod√®le ${model} non disponible ou erreur, fallback vers gpt-4o`);
      return await exponentialRetry(async () => {
        return await openai.chat.completions.create({
          model: 'gpt-4o',
          temperature,
          messages,
          max_tokens
        });
      });
    }
    throw error;
  }
} 