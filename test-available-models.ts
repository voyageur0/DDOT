#!/usr/bin/env npx ts-node
require('dotenv').config();

import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'sk-dummy',
});

async function testAvailableModels() {
  console.log('üîç Test des mod√®les OpenAI disponibles\n');
  
  // Liste des mod√®les √† tester
  const modelsToTest = [
    'o3',           // Probablement pas encore disponible
    'o3-mini',      // Probablement pas encore disponible  
    'o1-preview',   // Devrait √™tre disponible
    'o1-mini',      // Devrait √™tre disponible
    'o1',           // Alias possible
    'gpt-4o',       // GPT-4 optimis√©
    'gpt-4o-mini',  // GPT-4 mini
    'gpt-4-turbo',  // GPT-4 Turbo
    'gpt-4',        // GPT-4 standard
    'gpt-3.5-turbo' // GPT-3.5 Turbo
  ];
  
  console.log('Test avec message simple pour chaque mod√®le:\n');
  
  for (const model of modelsToTest) {
    try {
      console.log(`Testing ${model}...`);
      
      // Configuration diff√©rente pour les mod√®les o1
      const isO1Model = model.startsWith('o1') || model.startsWith('o3');
      
      if (isO1Model) {
        // Les mod√®les o1 n'acceptent pas de system message
        const response = await openai.chat.completions.create({
          model,
          messages: [
            { role: 'user', content: '2+2=' }
          ],
          max_completion_tokens: 10
        });
        console.log(`‚úÖ ${model}: DISPONIBLE - R√©ponse: "${response.choices[0].message.content}"`);
      } else {
        // Mod√®les standards
        const response = await openai.chat.completions.create({
          model,
          messages: [
            { role: 'user', content: '2+2=' }
          ],
          max_tokens: 10,
          temperature: 0
        });
        console.log(`‚úÖ ${model}: DISPONIBLE - R√©ponse: "${response.choices[0].message.content}"`);
      }
      
    } catch (error: any) {
      if (error.status === 404) {
        console.log(`‚ùå ${model}: NON DISPONIBLE (404)`);
      } else if (error.status === 401) {
        console.log(`‚ùå ${model}: ERREUR AUTH (401) - V√©rifier la cl√© API`);
      } else if (error.status === 429) {
        console.log(`‚ö†Ô∏è ${model}: RATE LIMIT (429)`);
      } else {
        console.log(`‚ùå ${model}: ERREUR - ${error.message}`);
      }
    }
  }
  
  // Lister tous les mod√®les disponibles
  console.log('\nüìã Liste compl√®te des mod√®les disponibles:\n');
  try {
    const models = await openai.models.list();
    const modelNames = models.data
      .map(m => m.id)
      .sort()
      .filter(id => 
        id.includes('gpt') || 
        id.includes('o1') || 
        id.includes('o3') ||
        id.includes('davinci') ||
        id.includes('turbo')
      );
    
    console.log('Mod√®les de chat disponibles:');
    modelNames.forEach(name => console.log(`  - ${name}`));
    
  } catch (error: any) {
    console.error('Erreur lors de la r√©cup√©ration de la liste:', error.message);
  }
}

testAvailableModels().catch(console.error);